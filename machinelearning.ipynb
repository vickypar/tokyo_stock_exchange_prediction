{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3c9dfa0",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6d4146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "from math import sqrt\n",
    "from nsepy import get_history as gh\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from lightgbm import LGBMRegressor\n",
    "#import optuna.integration.lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from IPython.display import display\n",
    "import gc\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, confusion_matrix, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe19e1b",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "224d9e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "supplemental_prices = pd.read_csv('supplemental_files/stock_prices.csv')\n",
    "supplemental_sprices = pd.read_csv('supplemental_files/secondary_stock_prices.csv')\n",
    "prices = pd.read_csv('train_files/stock_prices.csv')\n",
    "stock_list = pd.read_csv('stock_list.csv')\n",
    "sprices = pd.read_csv('train_files/secondary_stock_prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62040279",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(supplemental_prices.info())\n",
    "display(supplemental_prices['Date'].unique())\n",
    "display(prices.info())\n",
    "display(stock_list.info())\n",
    "display(stock_list.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef55b8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices=prices.append(sprices,ignore_index=True)\n",
    "prices=prices.append(supplemental_prices,ignore_index=True)\n",
    "prices=prices.append(supplemental_sprices,ignore_index=True)\n",
    "prices=prices.drop(['RowId','ExpectedDividend'],axis=1)\n",
    "prices=prices.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710c62ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(prices['Date'],prices['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401e5bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1126f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices['Date'] = prices['Date'].str.replace('-','')\n",
    "train_prices = prices[prices['Date']<'20220201']\n",
    "train_prices = train_prices.drop(['Date'],axis=1)\n",
    "test_prices = prices[prices['Date']>='20220201']\n",
    "test_prices = test_prices.drop(['Date'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f4151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0e763f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_prices.pop('Target')\n",
    "y_test = test_prices.pop('Target')\n",
    "X_train = train_prices\n",
    "X_test = test_prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877dd4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featuring(train):\n",
    "    dfa=pd.DataFrame()\n",
    "    for code in train['SecuritiesCode'].unique():\n",
    "        df=train[train['SecuritiesCode']==code]\n",
    "        df=df.sort_values(by=['Date'], ascending=True)\n",
    "        df['RA_20'] = df.Close.rolling(5, min_periods=1).mean()\n",
    "        df['RA_40'] = df.Close.rolling(10, min_periods=1).mean()\n",
    "        df['RA_60'] = df.Close.rolling(15, min_periods=1).mean()\n",
    "        df['RA_80'] = df.Close.rolling(20, min_periods=1).mean()\n",
    "        dfa=dfa.append(df)\n",
    "    dfa['Quarter'] = dfa['Date'].apply(lambda time: pd.Timestamp(time).quarter)\n",
    "    dfa['year']=pd.to_numeric(dfa['Date'].str[0:4]).astype(float)\n",
    "    dfa['month']=pd.to_numeric(dfa['Date'].str[5:7]).astype(float)\n",
    "    dfa['day']=pd.to_numeric(dfa['Date'].str[8:10]).astype(float)\n",
    "    dfa['delta']=pd.to_numeric(dfa['High']-dfa['Low']).astype(float)\n",
    "    dfa['change']=pd.to_numeric(dfa['Close']-dfa['Open']).astype(float)\n",
    "    dfa=dfa[['Date','SecuritiesCode','delta','change','RA_20','RA_40','RA_60','year','month','day','Quarter']]\n",
    "    train=train.merge(dfa,how='left',on=['Date','SecuritiesCode'],suffixes=('', 'b')).set_axis(train.index)\n",
    "    train=train.drop(['Date'],axis=1)\n",
    "    #train=train.merge(stock_list, how='inner',on='SecuritiesCode',suffixes=('', 'b')).set_axis(train.index)\n",
    "    #train=train.drop(['EffectiveDate','Name','33SectorName','17SectorName','NewIndexSeriesSize','TradeDate','Closeb'],axis=1)\n",
    "    #dfa=dfa.join(stock_list,how='left',on='SecuritiesCode',rsuffix='b')\n",
    "    #dfa=dfa.drop(['SecuritiesCodeb','Name', 'NewMarketSegment','33SectorCode','33SectorName','17SectorCode','17SectorName','NewIndexSeriesSizeCode', 'NewIndexSeriesSize',\n",
    "    #   'TradeDate','Closeb','Universe0'],axis=1)\n",
    "    #dfa['Section']=label_encoder.fit_transform(dfa['Section/Products'])\n",
    "    #dfa=dfa.drop(['Section/Products'],axis=1)\n",
    "    #dfa.sort_index(inplace=True)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b712c836",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=featuring(X_train)\n",
    "X_test=featuring(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5552ae",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30093ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fc5021",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8a94529",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train the model\n",
    "model_linear = LinearRegression()\n",
    "model_linear.fit(X_train, y_train)\n",
    "\n",
    "## Predict in test data\n",
    "y_pred_linear = model_linear.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27e8762c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Mean Squared Error:  0.000695751848338965\n",
      "Mean Absolute Error:  0.016623766542252127\n",
      "Mean Absolute Percentage Error:  89837688114.40349\n",
      "Root Mean Squared Error:  0.02637710841504362\n"
     ]
    }
   ],
   "source": [
    "##Evaluate the model\n",
    "print(\"Linear Regression\")\n",
    "\n",
    "#Mean Squared Error (MSE)\n",
    "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
    "#Mean Absolute Error (MAE)\n",
    "mae_linear = mean_absolute_error(y_test, y_pred_linear)\n",
    "#Mean Absolute Percentage Error (MAPE)\n",
    "mape_linear = mean_absolute_percentage_error(y_test, y_pred_linear)\n",
    "#Root Mean Squared Error (RMSE)\n",
    "rmse_linear = mean_squared_error(y_test, y_pred_linear, squared = False)\n",
    "\n",
    "print(\"Mean Squared Error: \", mse_linear)\n",
    "print(\"Mean Absolute Error: \", mae_linear)\n",
    "print(\"Mean Absolute Percentage Error: \", mape_linear)\n",
    "print(\"Root Mean Squared Error: \", rmse_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c955ce72",
   "metadata": {},
   "source": [
    "## k - Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c0a6580",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train the model\n",
    "model_knn = KNeighborsRegressor(n_neighbors = 50)\n",
    "model_knn.fit(X_train, y_train)\n",
    "\n",
    "## Predict in test data\n",
    "y_pred_knn = model_knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4506e12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-Nearest Neighbor\n",
      "Mean Squared Error:  0.0007095019648995752\n",
      "Mean Absolute Error:  0.01695586332460318\n",
      "Mean Absolute Percentage Error:  727315081942.3413\n",
      "Root Mean Squared Error:  0.026636478087381885\n"
     ]
    }
   ],
   "source": [
    "##Evaluate the model\n",
    "print(\"k-Nearest Neighbor\")\n",
    "\n",
    "#Mean Squared Error (MSE)\n",
    "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
    "#Mean Absolute Error (MAE)\n",
    "mae_knn = mean_absolute_error(y_test, y_pred_knn)\n",
    "#Mean Absolute Percentage Error (MAPE)\n",
    "mape_knn = mean_absolute_percentage_error(y_test, y_pred_knn)\n",
    "#Root Mean Squared Error (RMSE)\n",
    "rmse_knn = mean_squared_error(y_test, y_pred_knn, squared = False)\n",
    "\n",
    "print(\"Mean Squared Error: \", mse_knn)\n",
    "print(\"Mean Absolute Error: \", mae_knn)\n",
    "print(\"Mean Absolute Percentage Error: \", mape_knn)\n",
    "print(\"Root Mean Squared Error: \", rmse_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602714da",
   "metadata": {},
   "source": [
    "## Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d5b569",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svr = SVR(kernel='linear') # Linear Kernel\n",
    "#Train the model using the training sets\n",
    "model_svr = model_svr.fit(X_train, y_train)\n",
    "#Predict the response for test dataset\n",
    "y_pred_svr = model_svr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc3f617",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Evaluate the model\n",
    "print(\"Support Vector Regressor\")\n",
    "\n",
    "#Mean Squared Error (MSE)\n",
    "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
    "#Mean Absolute Error (MAE)\n",
    "mae_svr = mean_absolute_error(y_test, y_pred_svr)\n",
    "#Mean Absolute Percentage Error (MAPE)\n",
    "mape_svr = mean_absolute_percentage_error(y_test, y_pred_svr)\n",
    "#Root Mean Squared Error (RMSE)\n",
    "rmse_svr = mean_squared_error(y_test, y_pred_svr, squared = False)\n",
    "\n",
    "print(\"Mean Squared Error: \", mse_svr)\n",
    "print(\"Mean Absolute Error: \", mae_svr)\n",
    "print(\"Mean Absolute Percentage Error: \", mape_svr)\n",
    "print(\"Root Mean Squared Error: \", rmse_svr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9362e0aa",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f565080",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train the model\n",
    "model_adaboost = AdaBoostRegressor(n_estimators = 100, learning_rate = 3, random_state = 0)\n",
    "model_adaboost = model_adaboost.fit(X_train, y_train)\n",
    "\n",
    "## Predict in test data\n",
    "y_pred_adaboost = model_adaboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b209a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Evaluate the model\n",
    "\n",
    "#Mean Squared Error (MSE)\n",
    "mse_adaboost = mean_squared_error(y_test, y_pred_adaboost)\n",
    "#Mean Absolute Error (MAE)\n",
    "mae_adaboost = mean_absolute_error(y_test, y_pred_adaboost)\n",
    "#Mean Absolute Percentage Error (MAPE)\n",
    "mape_adaboost = mean_absolute_percentage_error(y_test, y_pred_adaboost)\n",
    "#Root Mean Squared Error (RMSE)\n",
    "rmse_adaboost = mean_squared_error(y_test, y_pred_adaboost, squared = False)\n",
    "\n",
    "print(\"Mean Squared Error: \", mse_adaboost)\n",
    "print(\"Mean Absolute Error: \", mae_adaboost)\n",
    "print(\"Mean Absolute Percentage Error: \", mape_adaboost)\n",
    "print(\"Root Mean Squared Error: \", rmse_adaboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb19f7a",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9acb405",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train the model\n",
    "model_random_forest = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "model_random_forest = model_random_forest.fit(X_train, y_train);\n",
    "\n",
    "## Predict in test data\n",
    "y_pred_forest = model_random_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00510f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Evaluate the model\n",
    "\n",
    "#Mean Squared Error (MSE)\n",
    "mse_random_forest = mean_squared_error(y_test, y_pred_forest)\n",
    "#Mean Absolute Error (MAE)\n",
    "mae_random_forest = mean_absolute_error(y_test, y_pred_forest)\n",
    "#Mean Absolute Percentage Error (MAPE)\n",
    "mape_random_forest = mean_absolute_percentage_error(y_test, y_pred_forest)\n",
    "#Root Mean Squared Error (RMSE)\n",
    "rmse_random_forest = mean_squared_error(y_test, y_pred_forest, squared = False)\n",
    "\n",
    "print(\"Mean Squared Error: \", mse_random_forest)\n",
    "print(\"Mean Absolute Error: \", mae_random_forest)\n",
    "print(\"Mean Absolute Percentage Error: \", mape_random_forest)\n",
    "print(\"Root Mean Squared Error: \", rmse_random_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712f1b38",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdfd2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train the model\n",
    "model_xgboost = xgb.XGBRegressor(n_estimators=800,\n",
    "                                 max_depth=16,\n",
    "                                 learning_rate=0.01,\n",
    "                                 subsample=0.5,\n",
    "                                 colsample_bytree=0.75,\n",
    "                                 missing=-999,\n",
    "                                 random_state=2020,\n",
    "                                 tree_method='gpu_hist')\n",
    "\n",
    "model_xgboost.fit(X_train, y_train, early_stopping_rounds=20, eval_set=[(X_test, y_test)], verbose=1)\n",
    "\n",
    "## Predict in test data\n",
    "y_pred_xgboost = model_xgboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de242da",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Evaluate the model\n",
    "\n",
    "#Mean Squared Error (MSE)\n",
    "mse_xgboost = mean_squared_error(y_test, y_pred_xgboost)\n",
    "#Mean Absolute Error (MAE)\n",
    "mae_xgboost = mean_absolute_error(y_test, y_pred_xgboost)\n",
    "#Mean Absolute Percentage Error (MAPE)\n",
    "mape_xgboost = mean_absolute_percentage_error(y_test, y_pred_xgboost)\n",
    "#Root Mean Squared Error (RMSE)\n",
    "rmse_xgboost = mean_squared_error(y_test, y_pred_xgboost, squared = False)\n",
    "\n",
    "print(\"Mean Squared Error: \", mse_xgboost)\n",
    "print(\"Mean Absolute Error: \", mae_xgboost)\n",
    "print(\"Mean Absolute Percentage Error: \", mape_xgboost)\n",
    "print(\"Root Mean Squared Error: \", rmse_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c862ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def calc_spread_return_sharpe(df: pd.DataFrame, portfolio_size: int = 200, toprank_weight_ratio: float = 2) -> float:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        df (pd.DataFrame): predicted results\n",
    "        portfolio_size (int): # of equities to buy/sell\n",
    "        toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n",
    "    Returns:\n",
    "        (float): sharpe ratio\n",
    "    \"\"\"\n",
    "    def _calc_spread_return_per_day(df, portfolio_size, toprank_weight_ratio):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df (pd.DataFrame): predicted results\n",
    "            portfolio_size (int): # of equities to buy/sell\n",
    "            toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n",
    "        Returns:\n",
    "            (float): spread return\n",
    "        \"\"\"\n",
    "        assert df['Rank'].min() == 0\n",
    "        assert df['Rank'].max() == len(df['Rank']) - 1\n",
    "        weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n",
    "        purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n",
    "        short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n",
    "        return purchase - short\n",
    "\n",
    "    buf = df.groupby('Date').apply(_calc_spread_return_per_day, portfolio_size, toprank_weight_ratio)\n",
    "    sharpe_ratio = buf.mean() / buf.std()\n",
    "    return sharpe_ratio\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6deb2c59",
   "metadata": {},
   "source": [
    "## Long Short-Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9967d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fd7cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc37f291",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857e8152",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape = (train_seq.shape[1], train_seq.shape[2])))\n",
    "\n",
    "model.add(Dropout(0.1)) \n",
    "model.add(LSTM(units=50))\n",
    "\n",
    "model.add(Dense(2))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b54ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=80,validation_data=(X_test, y_test), verbose=1)\n",
    "y_pred_lstm = model.predict(X_test)\n",
    "test_inverse_predicted = MMS.inverse_transform(y_pred_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca2075f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe04cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "price = pd.read_csv('supplemental_files/stock_prices.csv', parse_dates=[\"Date\"])\n",
    "prices.drop(['RowId','ExpectedDividend'], axis=1,inplace = True)\n",
    "df = df[df['Open'].notna()]\n",
    "df = df[df['Target'].notna()]\n",
    "df2 = df.copy()\n",
    "df2['Date'] = df['Date'].dt.date\n",
    "df2['date_delta'] = (df2['Date'] - df2['Date'].min())  / np.timedelta64(1,'D')\n",
    "df2['weekday'] = df2['Date'].apply(lambda time: time.weekday())\n",
    "df2['Quarter'] = df2['Date'].apply(lambda time: pd.Timestamp(time).quarter)\n",
    "df2.drop(['Date'],axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41becd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = data2.iloc[:, 1:2].values\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(train_set)\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(60, 1482):\n",
    "    X_train.append(training_set_scaled[i-60:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0]) \n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "regressor = Sequential()\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(Dense(units = 1))\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "regressor.fit(X_train, y_train, epochs = 15, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa939ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = data2.iloc[:, 1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c558ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ed74f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cf487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = dt.datetime(2013,1,1)\n",
    "end = dt.datetime(2018,12,31)\n",
    "stk_data = gh(symbol='SBIN',start=start,end=end)\n",
    "stk_data['Date'] = stk_data.index\n",
    "data2 = pd.DataFrame(columns = ['Date', 'Open', 'High', 'Low', 'Close'])\n",
    "data2['Date'] = stk_data['Date']\n",
    "data2['Open'] = stk_data['Open']\n",
    "data2['High'] = stk_data['High']\n",
    "data2['Low'] = stk_data['Low']\n",
    "data2['Close'] = stk_data['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a36c619",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,14))\n",
    "plt.plot(stk_data['Close'])\n",
    "plt.title('Historical Stock Value')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67548e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stk_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63be136",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15447a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
